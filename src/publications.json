[
    {
        "title": "Journal and Peer-Reviewed Conference Papers",
        "list" : [
            {
                "harvardCitation" : "<b class='title-blues'>Nourani, M.</b>, Roy, C., Block, J.E., Honeycutt, D.R., Rahman, T., Ragan, E. and Gogate, V., 2021, April. Anchoring Bias Affects Mental Model Formation and User Reliance in Explainable AI Systems. In 26th International Conference on Intelligent User Interfaces (pp. 340-350). üèÜ <b style='color:var(--red-cabin);'> <i>Best Paper Award, Honorable Mention</i></b>",
                "link": "https://dl.acm.org/doi/10.1145/3397481.3450639",
                "nickname": "NouraniPineapple2021",
                "type": "Conference Paper",
                "video": "https://youtu.be/lHrLGD0560A"
            },
            {
                "harvardCitation" : "<b class='title-blues'>Nourani, M.</b>, King, J.T., and Ragan, E.D., 2020, October. The Role of Domain Expertise in User Trust and the Impact of First Impressions with Intelligent Systems.  In Proceedings of the AAAI Conference on Human Computation and Crowdsourcing (AAAI HCOMP). pp 1-10.",
                "link": "https://www.aaai.org/ojs/index.php/HCOMP/article/view/7469",
                "nickname": "NouraniBugs2020",
                "type": "Conference Paper",
                "video": "https://screencast-o-matic.com/watch/cY6jerKCYZ"
            },
            {
                "harvardCitation" : "Honeycutt, D., <b class='title-blues'>Nourani, M.</b>, and Ragan, E. 2020, October. Soliciting Human-in-the-Loop User Feedback for Interactive Machine Learning Reduces User Trust and Impressions of Model Accuracy. AAAI Conference on Human Computation and Crowdsourcing (AAAI HCOMP). pp 1-10.",
                "link": "https://www.aaai.org/ojs/index.php/HCOMP/article/view/7464",
                "nickname": "HoneycuttLoop2020",
                "type": "Conference Paper",
                "video": "https://screencast-o-matic.com/watch/cY6QrgKMb7"
            },
            {
                "harvardCitation" : "Li, Q., Chu, S.L., Rao, N., and <b class='title-blues'>Nourani, M.</b> 2020, October. Understanding the Effects of Explanation Types and User Motivations on Movie Recommender System Use. AAAI Conference on Human Computation and Crowdsourcing (AAAI HCOMP). pp 1-10.",
                "link": "https://www.aaai.org/ojs/index.php/HCOMP/article/view/7466",
                "nickname": "QingMovie2020",
                "type": "Conference Paper"
            },
            {
                "harvardCitation" : "Bolte,F., <b class='title-blues'>Nourani, M.</b>, Ragan, E.D., and Bruckner, S., 2020. Splitstreams: A visual metaphor for evolving hierarchies. In IEEE transactions on visualization and computer graphics (TVCG). doi.org/10.1109/TVCG.2020.2973564",
                "link": "https://ieeexplore.ieee.org/document/8998355",
                "nickname": "BolteSplits2020",
                "type": "Journal Article",
                "video": "https://www.youtube.com/watch?v=mIadBtuBq1w&feature=youtu.be&t=5369"
            },
            {
                "harvardCitation" : "<b class='title-blues'>Nourani, M.</b>, Kabir, S., Mohseni, S. and Ragan, E.D., 2019, October. The Effects of Meaningful and Meaningless Explanations on Trust and Perceived System Accuracy in Intelligent Systems. In Proceedings of the AAAI Conference on Human Computation and Crowdsourcing (Vol. 7, No. 1, pp. 97-105).",
                "link": "https://wvvw.aaai.org/ojs/index.php/HCOMP/article/view/5284",
                "nickname": "NouraniCats2019",
                "type": "Conference Paper"

            }
        ]
    },
    {
        "title": "Workshop papers, Extended Abstracts, and Presentations",
        "list": [
            {
                "harvardCitation" : "<b class='title-blues'>Nourani, M.</b>, Honeycutt, D.R., Block, J.E., Roy, C., Rahman, T., Ragan, E.D., and Gogate, V., 2020. Investigating the Importance of First Impressions and Explainable AI with Interactive Video Analysis. CHI'20 Extended Abstracts on Human Factors in Computing Systems  .",
                "link": "https://dl.acm.org/doi/abs/10.1145/3334480.3382967",
                "nickname": "LBWPineapple2020",
                "type": "Late-Breaking Work",
                "video": "https://youtu.be/7WYZRzJ_kwA"

            },
            {
                "harvardCitation" : "Roy, C., Shanbhag, M., <b class='title-blues'>Nourani, M.</b>, Rahman, T., Kabir, S., Gogate, V., Ruozzi, N. and Ragan, E.D., 2019. Explainable Activity Recognition in Videos. In IUI Workshops.",
                "link": "https://explainablesystems.comp.nus.edu.sg/2019/wp-content/uploads/2019/02/IUI19WS-ExSS2019-8.pdf",
                "nickname": "RoyExSS2019",
                "type": "Workshop paper"

            },
            {
                "harvardCitation" : "Roy, C., <b class='title-blues'>Nourani, M.</b>, Shanbhag, M., Kabir, S., Rahman, T., Ragan, E., Ruozzi, N. and Gogate, V. (2019). Explainable Activity Recognition in Videos using Dynamic Cutset Networks. 3rd Workshop of Tractable Probabilistic Modeling (TPM 2019)",
                "link": "",
                "nickname": "",
                "type": "Presentation"

            }
        ]
    },
    {
        "title": "Under-review (submitted to arXiv)",
        "list": [
            {
                "harvardCitation" : "<b class='title-blues'>Nourani, M.</b>, Roy, C., Rahman, T., Ragan, E.D., Ruozzi, N., and Gogate, V. 2020. Don't Explain without Verifying Veracity: An Evaluation of Explainable AI with Video Activity Recognition. arXiv:2005.02335",
                "link": "https://arxiv.org/abs/2005.02335",
                "nickname": "NouraniQcumber",
                "type": "arXiv Paper"
            }
        ]
    }
]
